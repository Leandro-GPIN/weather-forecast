{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "previsao_tempo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmRbyvbDnir0WXrff8p0pT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leandro-GPIN/weather-forecast/blob/main/previsao_tempo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1tzTCnPAX8B",
        "outputId": "b80acfbf-99d0-49d1-d4f8-2fb07e2197bd"
      },
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Dataset : https://tempo.inmet.gov.br/ \n",
        "# Produto : Tabela de dados das estações\n",
        "# Tipo    : Convencionais\n",
        "# Estação : Porto Alegre (83967)\n",
        "# Periodo : 01/01/2000 a 28/03/2021\n",
        "\n",
        "# Lendo dataset no formato CSV sepado por ponto e virgula.\n",
        "df = pd.read_csv('poa.csv', skiprows=1, delimiter=';', decimal=\",\")\n",
        "\n",
        "# Substituindo valores nulos por zero na coluna de chuva\n",
        "df['Chuva [Diaria] (mm)'] = df['Chuva [Diaria] (mm)'].fillna(0)\n",
        "\n",
        "# Substituindo valores acima de zero para a coluna chuva, chuva será categorica 0 ou 1\n",
        "df.loc[(df['Chuva [Diaria] (mm)'] > 0.0), 'Chuva [Diaria] (mm)']= 1\n",
        "\n",
        "# Dividindo a coluna \"Data\" em \"Dia\", \"Mes\" e \"Ano\"\n",
        "df[['Dia','Mes', 'Ano']] = df[\"Data\"].str.split(\"/\",expand=True,)\n",
        "\n",
        "# Atribuindo o tipo inteiro para \"Dia\", \"Mes\" e \"Ano\"\n",
        "df[['Dia','Mes', 'Ano']] = df[['Dia','Mes', 'Ano']].astype(int)\n",
        "\n",
        "# Removendo a linha que as variaveis são nulas\n",
        "df = df.dropna(subset=['Temp. [Hora] (C)', 'Umi. (%)', 'Pressao (hPa)', 'Vel. Vento (m/s)', 'Dir. Vento (m/s)', 'Nebulosidade (Decimos)'])\n",
        "\n",
        "# Normalizando\n",
        "df['Dia'] = df[\"Dia\"]  / df[\"Dia\"].abs().max()\n",
        "df['Mes'] = df[\"Mes\"]  / df[\"Mes\"].abs().max()\n",
        "df['Ano'] = df[\"Ano\"]  / df[\"Ano\"].abs().max()\n",
        "df['Hora (UTC)'] = df[\"Hora (UTC)\"]  / df[\"Hora (UTC)\"].abs().max()\n",
        "df['Temp. [Hora] (C)'] = df[\"Temp. [Hora] (C)\"]  / df[\"Temp. [Hora] (C)\"].abs().max()\n",
        "df['Umi. (%)'] = df[\"Umi. (%)\"]  / df[\"Umi. (%)\"].abs().max()\n",
        "df['Pressao (hPa)'] = df[\"Pressao (hPa)\"]  / df[\"Pressao (hPa)\"].abs().max()\n",
        "df['Vel. Vento (m/s)'] = df[\"Vel. Vento (m/s)\"]  / df[\"Vel. Vento (m/s)\"].abs().max()\n",
        "df['Dir. Vento (m/s)'] = df[\"Dir. Vento (m/s)\"]  / df[\"Dir. Vento (m/s)\"].abs().max()\n",
        "df['Nebulosidade (Decimos)'] = df[\"Nebulosidade (Decimos)\"]  / df[\"Nebulosidade (Decimos)\"].abs().max()\n",
        "\n",
        "# Separando os conjuntos\n",
        "X = df[['Dia', 'Mes', \"Ano\",\"Hora (UTC)\" , \"Temp. [Hora] (C)\", \"Umi. (%)\", \"Pressao (hPa)\", \"Vel. Vento (m/s)\", \"Dir. Vento (m/s)\", \"Nebulosidade (Decimos)\"]]\n",
        "y = df['Chuva [Diaria] (mm)']\n",
        "\n",
        "# Criando conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# Nome dos calssificadores\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]\n",
        "\n",
        "# Instanciando os cassificadores\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "# Iteração sobre os classificadores\n",
        "for name, clf in zip(names, classifiers):\n",
        "  clf.fit(X_train, y_train)\n",
        "  score = clf.score(X_test, y_test)\n",
        "\n",
        "  # imprimindo os resultados\n",
        "  print(\"{} - {}\".format(score, name))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9027529495888452 - Nearest Neighbors\n",
            "0.8707543796925277 - Linear SVM\n",
            "0.9183053271362174 - RBF SVM\n",
            "0.9109760457633178 - Decision Tree\n",
            "0.8707543796925277 - Random Forest\n",
            "0.9109760457633178 - Neural Net\n",
            "0.9220593493028244 - AdaBoost\n",
            "0.8022881658920272 - Naive Bayes\n",
            "0.8017518770110833 - QDA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR6OOKOYAoB3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}